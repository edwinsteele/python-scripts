import HTMLParser, re
from calibre.web.feeds.news import BasicNewsRecipe

class AdvancedUserRecipe1299694372(BasicNewsRecipe):
    # Derived from upstream recipe at:
    # http://bazaar.launchpad.net/~kovid/calibre/trunk/view/head:/recipes/instapaper.recipe
    # Original authors: Darko Miletic, Stanislav Khromov
    title = u'Alternative Instapaper'
    __author__ = 'Edwin Steele, Darko Miletic, Stanislav Khromov'
    publisher = 'Instapaper.com'
    category = 'info, custom, Instapaper'

    # Add in a title from the article body in case it's not already there
    add_title = False
    #Set include_liked to true if you want to include liked items in your feed.
    include_liked = False
    #Set to true if you want to reverse article order
    reverse_article_order = False
    #Set the maximum amount of articles you'd like to receive here
    max_articles_per_feed = 30
    # Oldest article in days
    oldest_article = 0
    no_stylesheets = True
    remove_tags = [
        dict(name='div', attrs={'id':'text_controls_toggle'}), \
        dict(name='script'), \
        dict(name='div', attrs={'id':'text_controls'}), \
        dict(name='div', attrs={'id':'editing_controls'}), \
        dict(name='div', attrs={'class':'bar bottom'}), \
        dict(name='div', attrs={'id':'controlbar_container'}), \
        dict(name='div', attrs={'id':'footer'}), \
		 ]
    use_embedded_content = False
    needs_subscription = True
    INDEX = u'http://www.instapaper.com'
    LOGIN = INDEX + u'/user/login'
    
    feeds = [(u'Instapaper Unread', INDEX + u'/u')]
    if include_liked:
        feeds.append((u'Instapaper Liked', INDEX + u'/starred'))

    def get_browser(self):
        br = BasicNewsRecipe.get_browser()
        if self.username is not None:
            br.open(self.LOGIN)
            br.select_form(nr=0)
            br['username'] = self.username
            if self.password is not None:
                br['password'] = self.password
            br.submit()
        return br

    def parse_index(self):
        totalfeeds = []
        lfeeds = self.get_feeds()

        for feedobj in lfeeds:
            feedtitle, feedurl = feedobj
            self.report_progress(0, 'Fetching feed' + ' %s...' % \
                (feedtitle if feedtitle else feedurl))
            articles = []
            soup = self.index_to_soup(feedurl)
            for atag in soup.findAll('a', attrs={'class':'actionButton textButton'}):
                if atag.has_key('href'):
                    articles.append({'url':atag["href"]})
            totalfeeds.append((feedtitle, articles))
        return totalfeeds

    def print_version(self, url):
        return self.INDEX + url

    def populate_article_metadata(self, article, soup, first_fetch):
        wordCount = len(re.split("\W+", str(soup.find(id="story"))))
        if wordCount < 10:
            # We probably have one the content in a second body tag
            bodies = soup.findAll("body")
            if len(bodies) > 1:
                wordCount = len(re.split("\W+", str(bodies[1])))

        # Escape character references or entities with HTMLParser.unescape
        #  Use http://effbot.org/zone/re-sub.htm#unescape-html post 2.6
        #  because unescape is deprecated
        pars = HTMLParser.HTMLParser()
        article.title  = "[%s words] %s" % \
          (wordCount, pars.unescape(soup.find('title').contents[0].strip()))

    def postprocess_html(self, soup, first_fetch):
        if self.add_title:
            for link_tag in soup.findAll(attrs={"id" : "story"}):
                link_tag.insert(0, "<h1>%s</h1>" % (soup.find('title').contents[0].strip(),))
        return soup

